{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skpro introduction notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set-up instructions:** On binder, this should run out-of-the-box.\n",
    "\n",
    "To run this notebook as intended, ensure that `skpro` with basic dependency requirements is installed in your python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` provides `scikit-learn`-like, `scikit-base` compatible interfaces to:\n",
    "\n",
    "* tabular **supervised regressors with probabilistic prediction modes** - interval, quantile and distribution predictions\n",
    "* **performance metrics to evaluate probabilistic predictions**, e.g., pinball loss, empirical coverage, CRPS\n",
    "* **reductions** to turn non-probabilistic, `scikit-learn` regressors into probabilistic `skpro` regressors, such as bootstrap or conformal\n",
    "* tools for building **pipelines and composite machine learning models**, including tuning via probabilistic performance metrics\n",
    "* symbolic an lazy **probability distributions** with a value domain of `pandas.DataFrame`-s and a `pandas`-like interface\n",
    "\n",
    "**Section 1** provides an overview of common **probabilistic supervised regression workflows** supported by `skpro`.\n",
    "\n",
    "**Section 2** gives a detailed introduction to the different **prediction modes and performance metrics**.\n",
    "\n",
    "**Section 3** discusses **advanced composition patterns**, including various ways to add probabilistic capability to any `sklearn` regressor, pipeline building, tuning, ensembling.\n",
    "\n",
    "**Section 4** gives an introduction to how to write **custom estimators** compliant with the `skpro` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# hide warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic probabilistic supervised regression workflows <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` revolves around supervised probabilistic regressors:\n",
    "\n",
    "* `fit(X, y)` with tabular features `X`, labels `y`, same rows, both `pd.DataFrame`\n",
    "* `predict_interval(X_test)` for interval predictions of labels\n",
    "* `predict_quantiles(X_test)` for quantile predictions of labels\n",
    "* `predict_var(X_test)` for variance predictions of labels\n",
    "* `predict(X_test)` for mean predictions\n",
    "* `predict_proba(X_test)` for distributional prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 basic deployment workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` regressors are used via `fit` then `predict_proba` etc.\n",
    "\n",
    "Same as `sklearn` regressors - `X` and `y` should be `pd.DataFrame` (`numpy` is also ok but not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skpro.regression.residual import ResidualDouble\n",
    "\n",
    "# step 1: data specification\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "X_train, X_new, y_train, _ = train_test_split(X, y)\n",
    "\n",
    "# step 2: specifying the regressor\n",
    "# example - random forest for mean prediction\n",
    "# linear regression for variance prediction\n",
    "reg_mean = RandomForestRegressor()\n",
    "reg_resid = LinearRegression()\n",
    "reg_proba = ResidualDouble(reg_mean, reg_resid)\n",
    "\n",
    "# step 3: fitting the model to training data\n",
    "reg_proba.fit(X_train, y_train)\n",
    "\n",
    "# step 4: predicting labels on new data\n",
    "\n",
    "# probabilistic prediction modes - pick any or multiple\n",
    "# we show the return types in detail below\n",
    "\n",
    "# full distribution prediction\n",
    "y_pred_proba = reg_proba.predict_proba(X_new)\n",
    "\n",
    "# interval prediction\n",
    "y_pred_interval = reg_proba.predict_interval(X_new, coverage=0.9)\n",
    "\n",
    "# quantile prediction\n",
    "y_pred_quantiles = reg_proba.predict_quantiles(X_new, alpha=[0.05, 0.5, 0.95])\n",
    "\n",
    "# variance prediction\n",
    "y_pred_var = reg_proba.predict_var(X_new)\n",
    "\n",
    "# mean prediction is same as \"classical\" sklearn predict, also available\n",
    "y_pred_mean = reg_proba.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 distribution predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y_pred_proba` is an `skpro` distribution - it has index and columns like `pd.DataFrame`\n",
    "\n",
    "\"we predict that true labels are distributed according to `y_pred_proba`\"\n",
    "\n",
    "(here: distribution marginal by row/columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = reg_proba.predict_proba(X_new)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` distribution objects are pandas-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba.index  # same index as X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba.columns  # same columns as X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distribution objects have `sample` and methods such as `mean`, `var`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba.sample().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba.var().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 interval predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interval prediction `y_pred_interval` is a `pd.DataFrame`:\n",
    "\n",
    "* rows are the same as `X_new`\n",
    "* columns indicate variables, nominal coverage, and bottom/upper bound\n",
    "\n",
    "\"we predict that value in row falls between bottom/upper with 90% chance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_interval = reg_proba.predict_interval(X_new, coverage=0.9)\n",
    "y_pred_interval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 quantile predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quantile prediction `y_pred_quantiles` is a `pd.DataFrame`:\n",
    "\n",
    "* rows are the same as `X_new`\n",
    "* columns indicate variables, quantile points\n",
    "\n",
    "\"we predict the 5%, 50%, 95% quantile points for the row to be here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_quantiles = reg_proba.predict_quantiles(X_new, alpha=[0.05, 0.5, 0.95])\n",
    "y_pred_quantiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 mean and variance predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean and variance predictions `y_pred_mean`, `y_pred_var` are `pd.DataFrame`-s:\n",
    "\n",
    "* rows are the same as `X_new`\n",
    "* columns are the same as `X_new`\n",
    "\n",
    "entries are predictive mean and variance in row/column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mean = reg_proba.predict(X_new)\n",
    "y_pred_var = reg_proba.predict_var(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the same as taking the distribution prediction and taking mean/variance\n",
    "\n",
    "(for distribution objects that estimate these precisely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba.var().head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 simple evaluation workflow for probabilistic predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for simple evaluation:\n",
    "\n",
    "1. split the data into train/test set\n",
    "2. make predictions of either type for test features\n",
    "3. compute metric on test set, comparing test predictions to hend out test labels\n",
    "\n",
    "Note:\n",
    "\n",
    "* metrics will compare tabular ground truth to probabilistic prediction\n",
    "* the metric will needs to be of a compatible type, e.g., for proba predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skpro.metrics import CRPS\n",
    "from skpro.regression.residual import ResidualDouble\n",
    "\n",
    "# step 1: data specification\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# step 2: specifying the regressor\n",
    "# example - linear regression for mean prediction\n",
    "# random forest for variance prediction\n",
    "reg_mean = LinearRegression()\n",
    "reg_resid = RandomForestRegressor()\n",
    "reg_proba = ResidualDouble(reg_mean, reg_resid)\n",
    "\n",
    "# step 3: fitting the model to training data\n",
    "reg_proba.fit(X_train, y_train)\n",
    "\n",
    "# step 4: predicting labels on new data\n",
    "y_pred_proba = reg_proba.predict_proba(X_test)\n",
    "\n",
    "# step 5: specifying evaluation metric\n",
    "metric = CRPS()\n",
    "\n",
    "# step 6: evaluat metric, compare predictions to actuals\n",
    "metric(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do we know that metric is of right type? Via `scitype:y_pred` tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.get_tags()\n",
    "# scitype:y_pred is pred_proba - for proba predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do we find metrics for a prediction type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.registry import all_objects\n",
    "\n",
    "all_objects(\"metric\", as_dataframe=True, return_tags=\"scitype:y_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra note: quantile metrics can be applied to interval predictions as well\n",
    "\n",
    "more details on metrics below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 diagnostic visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some useful diagnostic visualisations: variants of crossplots for probabilistic predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. crossplot ground truth vs prediction intervals.\n",
    "\n",
    "Works with both proba and interval predictions.\n",
    "\n",
    "What to look for: intervals shouhld cut through the x = y line (green points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.utils.plotting import plot_crossplot_interval\n",
    "\n",
    "plot_crossplot_interval(y_test, y_pred_proba, coverage=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.utils.plotting import plot_crossplot_interval\n",
    "\n",
    "y_pred_interval = reg_proba.predict_interval(X_test, coverage=0.9)\n",
    "plot_crossplot_interval(y_test, y_pred_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. crossplot residuals vs predictive standard deviation\n",
    "\n",
    "Works with both proba and variance predictions.\n",
    "\n",
    "What to look for: should be close to a line, high linear correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.utils.plotting import plot_crossplot_std\n",
    "\n",
    "plot_crossplot_std(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.utils.plotting import plot_crossplot_std\n",
    "\n",
    "y_pred_var = reg_proba.predict_var(X_test)\n",
    "plot_crossplot_std(y_test, y_pred_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.utils.plotting import plot_crossplot_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 searching for probabilistic regressors and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all objects in `skpro` are indexed via the `registry` utility `all_objects`.\n",
    "\n",
    "To find probabilistic supervised regressors, use `all_objects` with the type `regressor_proba`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.registry import all_objects\n",
    "\n",
    "all_objects(\"regressor_proba\", as_dataframe=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a full list can also be found in the online API reference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e631b8a076cc106144e9b132b7d31cae2f1e2660b47e5f9fcb0397caae5fbd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
