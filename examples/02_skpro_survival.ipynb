{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time-to-event modelling and survival prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set-up instructions:** On binder, this should run out-of-the-box.\n",
    "\n",
    "To run locally instead, ensure that `skpro` with basic dependency requirements is installed in your python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` provides a unified interface to time-to-event prediction models, also known as survival prediction models.\n",
    "\n",
    "**Time-to-event prediction** is a form of probabilistic regression where **labels can be \"censored\"**, i.e., of the form \"time is t or later\" instead of exat observations.\n",
    "\n",
    "**Section 1** provides an overview of the basic **time-to-event prediction workflows** supported by `skpro`.\n",
    "\n",
    "**Section 2** showcases **performance metrics and benchmarking** for time-to-event prediction with censored data.\n",
    "\n",
    "**Section 3** discusses **advanced composition patterns**, including various ways to leverage `sklearn` regressors for time-to-event prediction with censored data.\n",
    "\n",
    "**Section 4** gives an introduction to how to write **custom estimators** compliant with the `skpro` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic survival prediction interface <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section:\n",
    "\n",
    "* explanation of censored time-to-event data\n",
    "* `skpro` time-to-event/survival prediction interface\n",
    "* metrics, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 data representation, censoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survival prediction or time-to-event prediction can be seen a generalization of probabilistic supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Each sample consists of:\n",
    "\n",
    "* a feature vector, row of a data frame\n",
    "* a label, which can be an exact time of occurrence, or a statement about \"time was t or later\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated toy datset, lung cancer survival times\n",
    "import numpy as np\n",
    "\n",
    "# demographics - age and smoker yes/no\n",
    "age = np.random.uniform(low=20, high=100, size=50)\n",
    "smoker = np.random.binomial(1, 0.3, size=50)\n",
    "\n",
    "# actual survival time\n",
    "scale = 200 / (0.5 * age + 30 * smoker)\n",
    "survival = scale * np.random.weibull(1, size=50)\n",
    "\n",
    "# patients are observed only for 5 years\n",
    "# if they surviva 5 years, we know they survived 5 years, but not exact time of death\n",
    "censored = survival > 5\n",
    "observation = np.minimum(survival, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` represents this information in an `sklearn`-like interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# features\n",
    "X = pd.DataFrame({\"age\": age, \"smoker\": smoker})\n",
    "\n",
    "# time of survival or censoring\n",
    "y = pd.DataFrame({\"time\": observation})\n",
    "\n",
    "# indicator whether event was observed or censored\n",
    "# censored = 1/True, observed = 0/False\n",
    "# variable names should be the same as for y\n",
    "C = pd.DataFrame({\"time\": censored})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 basic survival prediction workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "survival prediction is the task:\n",
    "\n",
    "* given censored time-to-event labels and features, `X`, `y`, `C`\n",
    "* learn a model that can predict `y` if it were uncensored, i.e., the true event time\n",
    "* the prediction should take the form of a survival function or probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` survival predictors extend the interface of probabilistic regressors:\n",
    "\n",
    "* `fit(X, y, C=None)`, with `X`, `y`, `C` as above; if `C=None`, all observations are uncensored\n",
    "* `predict(X_test)` for mean survival time predictions\n",
    "* `predict_proba(X_test)` for distributional predictions\n",
    "\n",
    "Other prediction methods - `predict_interval`, `predict_quantiles`, `predict_var` - also generalize the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `C` is optional, and means \"uncensored\" if not passed, all survival prediction models can be used as supervised probabilistic regressors.\n",
    "\n",
    "Using probabilistic regressors as survival models is similarly possible, to be revisited later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic deployment workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skpro.survival.coxph import CoxPH\n",
    "\n",
    "# step 1: data specification\n",
    "# X, y, C, as above\n",
    "X_train, X_new, y_train, _, C_train, _ = train_test_split(X, y, C)\n",
    "\n",
    "# step 2: specifying the regressor\n",
    "# example - Cox proportional hazards model from statsmodels\n",
    "surv_model_cox = CoxPH()\n",
    "\n",
    "# step 3: fitting the model to training data\n",
    "surv_model_cox.fit(X_train, y_train, C_train)\n",
    "\n",
    "# step 4: predicting labels on new data\n",
    "\n",
    "# full distribution prediction\n",
    "y_pred_proba_cox = surv_model_cox.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean predicted survival time\n",
    "y_pred_proba_cox.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of survival functions\n",
    "y_pred_proba_cox.iloc[range(5)].plot(\"surv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting survival funtions in one figure, smokers in red\n",
    "from matplotlib.pyplot import subplots\n",
    "\n",
    "_, ax = subplots()\n",
    "\n",
    "for i in range(len(y_pred_proba_cox)):\n",
    "    ax = y_pred_proba_cox.iat[i, 0].plot(\"surv\", ax=ax, color=[\"b\", \"r\"][smoker[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 survival prediction with parametric predictive distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example: using an accelerated failure time model with Weibull hazard\n",
    "\n",
    "same workflow, only using different model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skpro.survival.aft import AFTWeibull\n",
    "\n",
    "# step 1: data specification\n",
    "# X, y, C, as above\n",
    "X_train, X_new, y_train, _, C_train, _ = train_test_split(X, y, C)\n",
    "\n",
    "# step 2: specifying the regressor\n",
    "# example - Cox proportional hazards model from statsmodels\n",
    "surv_model_aft = AFTWeibull()\n",
    "\n",
    "# step 3: fitting the model to training data\n",
    "surv_model_aft.fit(X_train, y_train, C_train)\n",
    "\n",
    "# step 4: predicting labels on new data\n",
    "\n",
    "# full distribution prediction\n",
    "y_pred_proba_aft = surv_model_aft.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting survival funtions in one figure, smokers in red\n",
    "from matplotlib.pyplot import subplots\n",
    "\n",
    "_, ax = subplots()\n",
    "\n",
    "for i in range(len(y_pred_proba_cox)):\n",
    "    ax = y_pred_proba_aft.iat[i, 0].plot(\n",
    "        \"surv\", ax=ax, color=[\"b\", \"r\"][smoker[i]], x_bounds=[0, 5]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hazard functions can be plotted the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of hazard functions\n",
    "y_pred_proba_aft.iloc[range(5)].plot(\"haz\", x_bounds=[0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting survival funtions in one figure, smokers in red\n",
    "from matplotlib.pyplot import subplots\n",
    "\n",
    "_, ax = subplots()\n",
    "\n",
    "for i in range(len(y_pred_proba_aft)):\n",
    "    ax = y_pred_proba_aft.iat[i, 0].plot(\n",
    "        \"haz\", ax=ax, color=[\"b\", \"r\"][smoker[i]], x_bounds=[0, 5]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated scale parameter\n",
    "y_pred_proba_aft.to_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual Weibull scale parameter to compare\n",
    "# unknown in a real scenario, but we know since we simulated the data\n",
    "scale[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 finding time-to-event prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-to-event (aka survival) prediction models are probabilistic regressors.\n",
    "\n",
    "I.e., the type is `regressor_proba`, as for probabilistic regressors.\n",
    "\n",
    "All probabilistic regressors can be used with for survival prediction as above.\n",
    "\n",
    "But, only models with the `\"capability:survival\"` tag set to `True` use the censoring information in `C`.\n",
    "\n",
    "Other models ignore `C`, which will lead to biased predictions (see section 3 on addressing this).\n",
    "\n",
    "The `all_objects` utility can be used to retrieve time-to-event prediction models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.registry import all_objects\n",
    "\n",
    "# time-to-event predictors have \"regressor_proba\" type, i.e., probabilistic regressors\n",
    "# the tag \"capability:survival\" = True indicates models that make use of C\n",
    "all_objects(\n",
    "    \"regressor_proba\", as_dataframe=True, filter_tags={\"capability:survival\": True}\n",
    ").head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 simple evaluation workflow for time-to-event predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for simple evaluation:\n",
    "\n",
    "1. split the data into train/test set - including the censoring variable\n",
    "2. make predictions of either type for test features\n",
    "3. compute metric on test set, comparing test predictions to held out test observations,\n",
    "  including censoring indicsator\n",
    "\n",
    "Note:\n",
    "\n",
    "* metrics will compare probabilistic prediction to tabular ground truth and\n",
    "  censoring indicator\n",
    "* the metric needs to be of a compatible type, e.g., for distribution predictions\n",
    "* special survival metrics are avaliable to take into account censoring;\n",
    "  if a non-survival metric is used, the censoring indicator will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skpro.metrics import ConcordanceHarrell\n",
    "from skpro.survival.coxph import CoxPH\n",
    "\n",
    "# step 1: data specification\n",
    "X_train, X_test, y_train, y_test, C_train, C_test = train_test_split(X, y, C)\n",
    "\n",
    "# step 2: specifying the regressor\n",
    "# example - Cox proportional hazards model from statsmodels\n",
    "surv_model = CoxPH()\n",
    "\n",
    "# step 3: fitting the model to training data\n",
    "surv_model.fit(X_train, y_train, C_train)\n",
    "\n",
    "# step 4: predicting labels on new data\n",
    "y_pred_proba = surv_model.predict_proba(X_test)\n",
    "\n",
    "# step 5: specifying evaluation metric\n",
    "metric = ConcordanceHarrell()\n",
    "\n",
    "# step 6: evaluate metric, compare predictions to actuals\n",
    "metric(y_test, y_pred_proba, C_true=C_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do we know that metric is a genuine survival metric?\n",
    "\n",
    "Via the `capability:survival` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.get_tags()\n",
    "# capability:survival is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do we find specialized survival metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.registry import all_objects\n",
    "\n",
    "all_objects(\"metric\", as_dataframe=True, filter_tags={\"capability:survival\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All metrics can be applied to censored data:\n",
    "\n",
    "metrics with the tag being `False` will ignore the censoring variable.\n",
    "\n",
    "This will lead to bias in general, but can be justified if there is a low amount of censoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Benchmarking time-to-event models <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `benchmarking.evaluate` utility can be used for time-to-event models as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from skpro.benchmarking.evaluate import evaluate\n",
    "from skpro.metrics import ConcordanceHarrell\n",
    "from skpro.survival.coxph import CoxPH\n",
    "\n",
    "# 1. specify dataset\n",
    "# X, y, C are as above\n",
    "\n",
    "# 2. specify estimator\n",
    "estimator = CoxPH()\n",
    "\n",
    "# 3. specify cross-validation schema\n",
    "cv = KFold(n_splits=3)\n",
    "\n",
    "# 4. specify evaluation metric\n",
    "c_index = ConcordanceHarrell()\n",
    "\n",
    "# 5. evaluate - run the benchmark\n",
    "# C needs to be passed here\n",
    "# this will automatically pass it on the test set to the metric\n",
    "results = evaluate(estimator=estimator, X=X, y=y, C=C, cv=cv, scoring=c_index)\n",
    "\n",
    "# results are pd.DataFrame\n",
    "# each row is one repetition of the cross-validation on one fold fit/predict/evaluate\n",
    "# columns report performance, runtime, and other optional information (see docstring)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced composition patterns <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we introduce a number of composition patterns available in `skpro`:\n",
    "\n",
    "* reducer-wrappers that turn `sklearn` regressors into survival regressors\n",
    "* pipelines of `sklearn` transformers with `skpro` survival regressors\n",
    "* tuning `skpro` survival regressors via grid/random search, minimizing a probabilistic metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data used in this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test, C_train, C_test = train_test_split(X, y, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation metric used in this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.metrics import ConcordanceHarrell\n",
    "\n",
    "c_harrell = ConcordanceHarrell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Reducers to create survival regressors <a class=\"anchor\" id=\"section3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the three main reduction stratgies to create survival regressors:\n",
    "\n",
    "1. adding the capability to handle censoring information to a probabilistic supervised regressor\n",
    "2. the above, combined with any strategy to create a probabilistic regressor from an `sklearn` (non-probabilistic) regressors\n",
    "3. strategies that directly create a survival regressor from a tabular `sklearn` regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows examples for all the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 adding survival capability to a probabilistic regressor <a class=\"anchor\" id=\"section3_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this type of reduction strategy takes a probabilistic regressor and adds treatment for censored data.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* native use - every probabilistic regressor can be used as a survival regressor, ignoring `C`\n",
    "* `FitUncensored` - fits the model on the uncensored data only\n",
    "* `ConditionUncensored` - uses `C` as a feature in fitting, and sets it to `C=0` in `Predict`\n",
    "\n",
    "The first two strategies introduce bias into the model, and should only be applied when the censoring fraction is low.\n",
    "\n",
    "Example with `ConditionUncensored`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.regression.linear import GLMRegressor\n",
    "from skpro.survival.compose import ConditionUncensored\n",
    "\n",
    "# estimator specification - use any skpro regressor, including composites\n",
    "reg_proba = GLMRegressor()\n",
    "\n",
    "# turning the regressor into a survival predictor\n",
    "surv_model = ConditionUncensored(reg_proba)\n",
    "\n",
    "# fit and predict\n",
    "surv_model.fit(X_train, y_train, C_train)\n",
    "y_pred_proba = surv_model.predict_proba(X_test)\n",
    "\n",
    "# evaluate\n",
    "c_harrell(y_test, y_pred_proba, C_true=C_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 adding probabilistic then survival capability to `sklearn` regressor <a class=\"anchor\" id=\"section3_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skpro.survival.compose import ConditionUncensored\n",
    "\n",
    "\n",
    "from skpro.regression.residual import ResidualDouble\n",
    "\n",
    "# estimator specification - use any skpro regressor, including composites\n",
    "reg_mean = RandomForestRegressor()\n",
    "reg_resid = RandomForestRegressor()\n",
    "reg_proba = ResidualDouble(reg_mean, reg_resid)\n",
    "\n",
    "# turning the regressor into a survival predictor\n",
    "surv_model = ConditionUncensored(reg_proba)\n",
    "\n",
    "# fit and predict\n",
    "surv_model.fit(X_train, y_train, C_train)\n",
    "y_pred_proba = surv_model.predict_proba(X_test)\n",
    "\n",
    "# evaluate\n",
    "c_harrell(y_test, y_pred_proba, C_true=C_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 bootstrap prediction intervals <a class=\"anchor\" id=\"section3_1_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from skpro.regression.bootstrap import BootstrapRegressor\n",
    "\n",
    "# estimator specification - use any sklearn regressor for reg_mean\n",
    "reg_mean = LinearRegression()\n",
    "reg_proba = BootstrapRegressor(reg_mean, n_bootstrap_samples=100)\n",
    "\n",
    "# fit and predict\n",
    "reg_proba.fit(X_train, y_train)\n",
    "y_pred_proba = reg_proba.predict_proba(X_test)\n",
    "\n",
    "# evaluate\n",
    "c_harrell(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pipelines of `skpro` survival regressors and `sklearn` transformers <a class=\"anchor\" id=\"section3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` survival regressors can be pipelined with `sklearn` transformers, using the `skpro` pipeline.\n",
    "\n",
    "This ensure presence of `predict_proba` etc in the pipeline object.\n",
    "\n",
    "The syntax is exactly the same as for `sklearn`'s pipeline,\n",
    "or the `skpro` pipeline with non-survival regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from skpro.regression.compose import Pipeline\n",
    "from skpro.survival.coxph import CoxPH\n",
    "\n",
    "# estimator specification\n",
    "surv_model = CoxPH()\n",
    "\n",
    "# pipeline is specified as a list of tuples (name, estimator)\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", Imputer()),  # an sklearn transformer\n",
    "        (\"scaler\", MinMaxScaler()),  # an sklearn transformer\n",
    "        (\"regressor\", surv_model),  # an skpro regressor\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pipeline behaves as any skpro regressor\n",
    "pipe.fit(X_train, y_train, C_train)\n",
    "y_pred = pipe.predict(X=X_test)\n",
    "y_pred_proba = pipe.predict_proba(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the pipeline provides the familiar nested `get_params`, `set_params` interface:\n",
    "\n",
    "nested parameters are keyed `componentname__parametername`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipelines can also be created via simple lists of estimators,\n",
    "\n",
    "in this case names are generated automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline is specified as a list of tuples (name, estimator)\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        Imputer(),  # an sklearn transformer\n",
    "        MinMaxScaler(),  # an sklearn transformer\n",
    "        surv_model,  # an skpro regressor\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Tuning of `skpro` regressors via grid and random search <a class=\"anchor\" id=\"section3_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` provides grid and random search tuners to tune arbitrary probabilistic regressors,\n",
    "\n",
    "using probabilistic metrics.\n",
    "\n",
    "Survival metrics can be used to tune survival regressors, same as non-survival regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from skpro.metrics import ConcordanceHarrell\n",
    "from skpro.model_selection import GridSearchCV\n",
    "from skpro.survival.coxph import CoxPH\n",
    "\n",
    "# cross-validation specification for tuner\n",
    "cv = KFold(n_splits=3)\n",
    "\n",
    "# estimator to be tuned\n",
    "estimator = CoxPH()\n",
    "\n",
    "# tuning grid - partial likelihood or elastic net penalty?\n",
    "param_grid = {\"estimator__method\": [\"lpl\", \"elastic_net\"]}\n",
    "\n",
    "# metric to be optimized\n",
    "c_harrell = ConcordanceHarrell()\n",
    "\n",
    "# specification of the grid search tuner\n",
    "gscv = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=c_harrell,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the grid search tuner behaves like any `skpro` survival regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.fit(X_train, y_train, V_train)\n",
    "y_pred = gscv.predict(X_test)\n",
    "y_pred_proba = gscv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random search is similar, except that instead of a grid a parameter sampler should be specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.model_selection import RandomizedSearchCV\n",
    "\n",
    "# only difference to GridSearchCV is the param_distributions argument\n",
    "\n",
    "# specification of the random search parameter sampler\n",
    "param_distributions = {\"estimator__method\": [\"lpl\", \"elastic_net\"]}\n",
    "\n",
    "# specification of the random search tuner\n",
    "rscv = RandomizedSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_distributions=param_distributions,\n",
    "    cv=cv,\n",
    "    scoring=c_harrell,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Bagging/mixture ensemble of survival regressors <a class=\"anchor\" id=\"section3_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical bagging does the following, for a wrapped estimator:\n",
    "\n",
    "In `fit`:\n",
    "\n",
    "1. subsample rows and/or columns of `X`, `y`, `C` to `X_subs`, `y_subs`, `C_subs`\n",
    "2. fit clone of wrapped estimator to `X_subs`, `y_subs`, `C_subs`\n",
    "3. Repeat 1-2 `n_estimators` times, store that many fitted clones.\n",
    "\n",
    "In `predict`, for `X_test`:\n",
    "\n",
    "1. for all fitted clones, obtain predictions on `X_test` - these are distributions\n",
    "2. return the uniform mixture of these distributions, per test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skpro.regression.ensemble import BaggingRegressor\n",
    "from skpro.survival.coxph import CoxPH\n",
    "\n",
    "survival_model = CoxPH()\n",
    "\n",
    "ens = BaggingRegressor(survival_model, n_estimators=10)\n",
    "ens.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ens.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred is a mixture distribution!\n",
    "str(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(x) for x in y_pred.distributions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extension guide - implementing your own time-to-event regressor <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`skpro` is meant to be easily extensible, for direct contribution to `skpro` as well as for local/private extension with custom methods.\n",
    "\n",
    "To get started:\n",
    "\n",
    "* Follow the [\"implementing estimator\" developer guide](https://skpro.readthedocs.io/en/stable/developer_guide/add_estimators.html)\n",
    "* Use the [survival regressor template](https://github.com/sktime/skpro/blob/main/extension_templates/survival.py) to get started\n",
    "\n",
    "1. Read through the [survival regression extension template](https://github.com/sktime/skpro/blob/main/extension_templates/survival.py) - this is a `python` file with `todo` blocks that mark the places in which changes need to be added.\n",
    "2. Copy the proba regressor extension template to a local folder in your own repository (local/private extension), or to a suitable location in your clone of the `skpro` or affiliated repository (if contributed extension), inside `skpro.survival`; rename the file and update the file docstring appropriately.\n",
    "3. Address the \"todo\" parts. Usually, this means: changing the name of the class, setting the tag values, specifying hyper-parameters, filling in `__init__`, `_fit`, and at least one of the probabilistic prediction methods, preferably `_predict_proba` (for details see the extension template). You can add private methods as long as they do not override the default public interface. For more details, see the extension template.\n",
    "4. To test your estimator manually: import your estimator and run it in the worfklows in Section 1; then use it in the compositors in Section 3.\n",
    "5. To test your estimator automatically: call `skpro.utils.check_estimator` on your estimator. You can call this on a class or object instance. Ensure you have specified test parameters in the `get_test_params` method, according to the extension template.\n",
    "\n",
    "In case of direct contribution to `skpro` or one of its affiliated packages, additionally:\n",
    "\n",
    "* Add yourself as an author and/or a maintainer for the new estimator file(s), via `\"authors\"` and `\"maintainers\"` tag.\n",
    "* Create a pull request that contains only the new estimators (and their inheritance tree, if it's not just one class), as well as the automated tests as described above.\n",
    "* In the pull request, describe the estimator and optimally provide a publication or other technical reference for the strategy it implements.\n",
    "* Before making the pull request, ensure that you have all necessary permissions to contribute the code to a permissive license (BSD-3) open source project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary<a class=\"anchor\" id=\"chapter5\"></a>\n",
    "\n",
    "* `skpro` is a unified interface toolbox for probabilistic supervised regression, that is, for prediction intervals, quantiles, fully distributional predictions, in a tabular regression setting. The interface is fully interoperable with `scikit-learn` and `scikit-base` interface specifications.\n",
    "\n",
    "* `skpro` comes with rich composition functionality that allows to build complex pipelines easily, and connect easily with other parts of the open source ecosystem, such as `scikit-learn` and individual algorithm libraries.\n",
    "\n",
    "* `skpro` is easy to extend, and comes with user friendly tools to facilitate implementing and testing your own probabilistic regressors and composition principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Credits:\n",
    "\n",
    "noteook creation: fkiraly\n",
    "\n",
    "skpro: https://github.com/sktime/skpro/blob/main/CONTRIBUTORS.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e631b8a076cc106144e9b132b7d31cae2f1e2660b47e5f9fcb0397caae5fbd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
