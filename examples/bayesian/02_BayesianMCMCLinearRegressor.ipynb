{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQirXZwKipys"
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preliz as pz\n",
    "import statsmodels.api as sm\n",
    "from IPython.display import Math, display\n",
    "from pymc_marketing.prior import Prior\n",
    "\n",
    "from skpro.regression.bayesian_mcmc import BayesianMCMCLinearRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_df(df, vmax=None, subset=None, cmap=\"coolwarm\", hide_index=False):\n",
    "    \"\"\"\n",
    "    Helper function - apply styling to a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to style.\n",
    "    vmax : float, optional\n",
    "        The maximum numeric value for the color spectrum.\n",
    "        Defaults to the max value in the DataFrame.\n",
    "    subset : list, optional\n",
    "        List of columns to which the gradient coloring/formatting is to be applied.\n",
    "    cmap : str, optional\n",
    "        The color map to apply for the gradient. Defaults to 'coolwarm'.\n",
    "    hide_index : bool, optional\n",
    "        If True, hide the DataFrame index in the output. Defaults to False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.io.formats.style.Styler\n",
    "        The styled DataFrame.\n",
    "    \"\"\"\n",
    "    # Determine the max value for the gradient if not provided\n",
    "    if vmax is None:\n",
    "        vmax = df.select_dtypes(include=[\"number\"]).max().max()\n",
    "\n",
    "    # If no subset provided, apply to all float columns by default\n",
    "    if subset is None:\n",
    "        subset = pd.IndexSlice[:, df.select_dtypes(include=[\"float64\"]).columns]\n",
    "\n",
    "    # Apply background gradient to numeric columns and format to 3 decimal points\n",
    "    styled_df = df.style.background_gradient(\n",
    "        cmap=cmap, axis=None, vmin=-vmax, vmax=vmax, subset=subset\n",
    "    ).format(\"{:.3f}\", subset=subset)\n",
    "\n",
    "    # Handle boolean columns with specific coloring (pink for False, lightblue for True)\n",
    "    bool_columns = df.select_dtypes(include=[\"bool\"]).columns\n",
    "\n",
    "    def color_boolean(val):\n",
    "        color = \"lightblue\" if val else \"pink\"\n",
    "        return f\"background-color: {color}\"\n",
    "\n",
    "    # Apply the boolean-specific styling if any boolean columns exist\n",
    "    if not bool_columns.empty:\n",
    "        styled_df = styled_df.applymap(color_boolean, subset=bool_columns)\n",
    "\n",
    "    # Hide the index if hide_index is True\n",
    "    if hide_index:\n",
    "        styled_df = styled_df.hide(axis=\"index\")\n",
    "\n",
    "    return styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAxBG7mR2Ar1"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdBN6n_m_0me"
   },
   "source": [
    "This notebook demonstrates how to use `skpro`'s `BayesianLinearRegressor`, which performs Bayesian linear regression powered by `PyMC` as the backend. The model defaults to weakly informative priors for both the intercept and slope, providing a flexible framework for capturing uncertainty in parameter estimates.\n",
    "\n",
    "In addition to showcasing the `BayesianLinearRegressor`, this notebook also revisits key aspects of the Bayesian workflow, its underlying theory and its comparison with the traditional Ordinary Least Squares (OLS) regression. \n",
    "\n",
    "Note: this notebook requires Python >= 3.10 to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RI4KS5__80T"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we aim to compare the performance of OLS and Bayesian Linear Regression by training both models on the same synthetic dataset and analyzing their results.\n",
    "\n",
    "We will see that compared to OLS regression, Bayesian Linear Regression offers several key advantages:\n",
    "\n",
    "1. **Incorporation of Prior Knowledge**: Bayesian regression allows you to incorporate prior beliefs about parameters, which can improve estimates, especially in cases where data is sparse.\n",
    "\n",
    "2. **Uncertainty Quantification**: It provides full posterior distributions for model parameters, enabling an intuitive assessment of uncertainty in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiSOh5L6AFuh"
   },
   "source": [
    "We will first create synthetic data with just two features (`feature1` and `feature2`) and 20 data points. The true relationship between the data $\\mathbf{x}$ and the target variable ($y_{\\text{true}}$) is given by the equation:\n",
    "\n",
    "\\begin{equation}\n",
    "y_{\\text{true}} = \\text{intercept}_{\\text{true}} + \\mathbf{x} \\cdot \\mathbf{m}_{\\text{true}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where $\\text{intercept}_{\\text{true}} = 1$ and $\\mathbf{m}_{\\text{true}} = [2, 3]$.\n",
    "\n",
    "The observed target values ($y_{\\text{train}}$) are generated by adding Gaussian noise to the true target values:\n",
    "\n",
    "\\begin{equation}\n",
    "y = y_{\\text{true}} + \\mathcal{N}(0, \\sigma_{\\text{true}})\n",
    "\\end{equation}\n",
    "Here, $\\sigma_{\\text{true}} = 0.5$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xo4qpkVhisFX",
    "outputId": "44218333-4b7d-42f7-9b02-b8f9a2caf30d"
   },
   "outputs": [],
   "source": [
    "N = 20\n",
    "np.random.seed(42)\n",
    "\n",
    "# Creating 10 random data points containing 2 features\n",
    "feature1 = np.random.uniform(0, 1, N)\n",
    "feature2 = np.random.uniform(0, 1, N)\n",
    "X_train = pd.DataFrame({\"feature1\": feature1, \"feature2\": feature2})\n",
    "\n",
    "# Set the relationship between the features and the target variable\n",
    "TRUE_INTERCEPT = 1\n",
    "TRUE_SLOPES = np.array([2, 3])\n",
    "TRUE_SIGMA = 0.5\n",
    "\n",
    "# Calculating the true target variable\n",
    "y_true = TRUE_INTERCEPT + np.dot(X_train, TRUE_SLOPES)\n",
    "\n",
    "y_train = y_true + np.random.normal(0, TRUE_SIGMA, size=len(X_train))\n",
    "\n",
    "# Combine the features and targets into a single DataFrame\n",
    "train_data = pd.concat(\n",
    "    [X_train, pd.Series(y_true, name=\"y_true\"), pd.Series(y_train, name=\"y_train\")],\n",
    "    axis=1,\n",
    ")\n",
    "train_data = train_data.sort_values(by=\"feature1\")\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "# Display the train_data DataFrame\n",
    "style_df(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUygtX7Ad698"
   },
   "source": [
    "The line chart below plots the relationship between `feature1` and the targets - both the theoretical `y_true`, represented by the red line, and the observed `y_train`, represented by the blue dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix feature1 and feature2 constants\n",
    "feature1_constant = train_data[\"feature1\"].mean()\n",
    "feature2_constant = train_data[\"feature2\"].mean()\n",
    "\n",
    "# Recalculate the true target `y_true` for a constant feature1\n",
    "y_true_fixed_feature1 = (\n",
    "    TRUE_INTERCEPT\n",
    "    + TRUE_SLOPES[0] * feature1_constant\n",
    "    + TRUE_SLOPES[1] * train_data[\"feature2\"]\n",
    ")\n",
    "\n",
    "# Recalculate the true target `y_true` for a constant feature2\n",
    "y_true_fixed_feature2 = (\n",
    "    TRUE_INTERCEPT\n",
    "    + TRUE_SLOPES[0] * train_data[\"feature1\"]\n",
    "    + TRUE_SLOPES[1] * feature2_constant\n",
    ")\n",
    "\n",
    "# Set up the plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot feature1 vs. y_train with feature2 constant\n",
    "axes[0].scatter(\n",
    "    train_data[\"feature1\"],\n",
    "    train_data[\"y_train\"],\n",
    "    label=\"Observed `y_train` (containing noise)\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "axes[0].plot(\n",
    "    train_data[\"feature1\"],\n",
    "    y_true_fixed_feature2,\n",
    "    color=\"red\",\n",
    "    label=f\"Theoretical `y_true` with feature2 fixed at {feature2_constant:.2f}\",\n",
    "    linewidth=2,\n",
    ")\n",
    "axes[0].set_xlabel(\"feature1\")\n",
    "axes[0].set_ylabel(\"y_true & y_train\")\n",
    "axes[0].set_title(f\"feature1 vs y_true & y_train\\n(feature2 = {feature2_constant:.2f})\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot feature2 vs. y_train with feature1 constant\n",
    "axes[1].scatter(\n",
    "    train_data[\"feature2\"],\n",
    "    train_data[\"y_train\"],\n",
    "    label=\"Observed `y_train` (containing noise)\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "axes[1].plot(\n",
    "    train_data[\"feature2\"],\n",
    "    y_true_fixed_feature1,\n",
    "    color=\"blue\",\n",
    "    label=f\"Theoretical `y_true` with feature1 fixed at {feature1_constant:.2f}\",\n",
    "    linewidth=2,\n",
    ")\n",
    "axes[1].set_xlabel(\"feature2\")\n",
    "axes[1].set_ylabel(\"y_true & y_train\")\n",
    "axes[1].set_title(f\"feature2 vs y_true & y_train\\n(feature1 = {feature1_constant:.2f})\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Improve spacing and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uB-IoGsjd3vA"
   },
   "source": [
    "We will also create synthetic **testing** data to evaluate the models' performance. The following code generates 10 new testing data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "X0ddXs1Ii0Yb",
    "outputId": "5f04ae6d-1dd8-475d-ac91-cc77564c3a24"
   },
   "outputs": [],
   "source": [
    "# Generate new data points for prediction with 2 features\n",
    "N_test = 10\n",
    "X_test = pd.DataFrame(\n",
    "    {\n",
    "        \"feature1\": np.random.uniform(0, 1, N_test),\n",
    "        \"feature2\": np.random.uniform(0, 1, N_test),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the first few rows of X_test\n",
    "style_df(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cwRHryxiA7t"
   },
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5LjqpmoiDV1"
   },
   "source": [
    "OLS is a method for estimating the linear relationship between independent variables (features) and a dependent variable (target).  The goal is to find a linear relationship by minimizing the sum of squared differences between the observed and predicted target values:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = \\arg\\min_{\\beta} \\sum_{i=1}^n (y_i - \\mathbf{x}_i^T \\beta)^2\n",
    "$$\n",
    "\n",
    "We’ll use the **`statsmodels`** library to train the OLS model. This will serve as a baseline for comparison with Bayesian Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7Af9sHKKdx8"
   },
   "outputs": [],
   "source": [
    "# Fit a linear regression model using statsmodels\n",
    "X_train_with_const = sm.add_constant(X_train)\n",
    "ols_model = sm.OLS(y_train, X_train_with_const).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T65gKYllh18N"
   },
   "source": [
    "When fitted to the data, the `ols_model` uses maximum likelihood estimation (MLE) to find the best estimates for the model parameters. A limitation of this approach is that it only provides point estimates—specific values for the slope and intercept—without any indication of the uncertainty or distribution of these estimates.\n",
    "\n",
    "The code below demonstrates how to extract these estimates from the `ols_model`. We see that the estimated slopes, intercept, and standard deviation are somewhat close to the true values we set during data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted values for y_train\n",
    "y_train_pred = ols_model.predict(X_train_with_const)\n",
    "residuals = y_train_pred - y_train\n",
    "\n",
    "\n",
    "# True model\n",
    "true_model_latex = rf\"\"\"\n",
    "\\text{{True data generating model:}} \\\\\n",
    "y_{{\\text{{true}}}} = {TRUE_SLOPES[0]:.2f} \\cdot x_1 +\n",
    "{TRUE_SLOPES[1]:.2f} \\cdot x_2 + {TRUE_INTERCEPT:.2f} \\\\\n",
    "\\text{{True standard deviation: }} \\sigma = {TRUE_SIGMA:.2f}\\\\\n",
    "\"\"\"\n",
    "\n",
    "# Estimated model\n",
    "estimated_model_latex = rf\"\"\"\n",
    "\\text{{Estimated MLE model:}} \\\\\n",
    "\\hat{{y}} = {ols_model.params.iloc[1]:.2f} \\cdot x_1 +\n",
    "{ols_model.params.iloc[2]:.2f} \\cdot x_2 + {ols_model.params.iloc[0]:.2f} \\\\\n",
    "\\text{{Standard deviation of residuals: }} \\hat{{\\sigma}} = {residuals.std():.2f}\n",
    "\"\"\"\n",
    "\n",
    "# Displaying the results using LaTeX\n",
    "display(Math(true_model_latex))\n",
    "display(Math(estimated_model_latex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evk3LGh6nEkU"
   },
   "source": [
    "\n",
    "Using the trained `ols_model`,  we can also create point predictions on the unseen `X_test` along with the corresponding confidence interval.\n",
    "\n",
    "The latter provides a range within which we expect the true parameter to lie with a certain level of confidence (e.g., 95%).\n",
    "\n",
    "In this code, we fix **`feature2`** at its mean value to isolate and visualize the influence of **`feature1`** on the target variable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix feature2 at its mean\n",
    "feature2_constant = X_test[\"feature2\"].mean()\n",
    "\n",
    "# Create a new test dataset with feature2 fixed at the constant value\n",
    "X_test_fixed_feature2 = X_test.copy()\n",
    "X_test_fixed_feature2[\"feature2\"] = feature2_constant\n",
    "\n",
    "# Predict y_test using the linear model after adding constant\n",
    "predictions_fixed_feature2 = ols_model.get_prediction(\n",
    "    sm.add_constant(X_test_fixed_feature2, has_constant=\"add\")\n",
    ")\n",
    "pred_summary_fixed_feature2 = predictions_fixed_feature2.summary_frame(alpha=0.05)\n",
    "\n",
    "# Extract predicted values and confidence intervals\n",
    "y_test_pred_fixed_feature2 = pred_summary_fixed_feature2[\"mean\"]\n",
    "conf_int_lower_fixed_feature2 = pred_summary_fixed_feature2[\"obs_ci_lower\"]\n",
    "conf_int_upper_fixed_feature2 = pred_summary_fixed_feature2[\"obs_ci_upper\"]\n",
    "\n",
    "sorted_indices = np.argsort(X_test[\"feature1\"])\n",
    "X_test_sorted = X_test[\"feature1\"].iloc[sorted_indices]\n",
    "y_test_pred_sorted = y_test_pred_fixed_feature2.iloc[sorted_indices]\n",
    "conf_int_lower_sorted = conf_int_lower_fixed_feature2.iloc[sorted_indices]\n",
    "conf_int_upper_sorted = conf_int_upper_fixed_feature2.iloc[sorted_indices]\n",
    "\n",
    "# Plot the predictions with the confidence intervals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test_sorted, y_test_pred_sorted, color=\"blue\", label=\"Predicted values\")\n",
    "plt.fill_between(\n",
    "    X_test_sorted,\n",
    "    conf_int_lower_sorted,\n",
    "    conf_int_upper_sorted,\n",
    "    color=\"lightblue\",\n",
    "    alpha=0.4,\n",
    "    label=\"95% Confidence Interval\",\n",
    ")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Predicted Target\")\n",
    "plt.title(f\"Predictions for X_test (Feature 2 fixed at {feature2_constant:.2f})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0cZgX_YnwA9"
   },
   "source": [
    "# Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrAkF1x4u6hn"
   },
   "source": [
    "Now let's switch our attention to bayesian linear regression. Bayesian linear regression estimates the relationship between variables by incorporating prior knowledge or beliefs along with the observed data. Instead of providing single point estimates for the model parameters (like the slope and intercept), it calculates their probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX3zjVyq4WsM"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVVm_Idgo0Ac"
   },
   "source": [
    "In this section, we will explore the theoretical framework used in Bayesian linear regression.\n",
    "\n",
    "Bayesian linear regression directly applies Bayes' Theorem to estimate the posterior distributions of the model parameters. As a reminder, here is the Bayes Theorem:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\theta \\mid D) &= \\frac{P(D \\mid \\theta) \\times P(\\theta)}{P(D)} \\\\\n",
    "\\text{posterior} &= \\frac{\\text{likelihood} \\times \\text{prior}}{\\text{marginal likelihood}}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\theta$ represents the model parameters, which in our case consist of the intercept $\\beta_{0}$, the slopes $\\beta$ and the noise $\\sigma$\n",
    "- $D$ represents the observed training data, which consist of $\\mathbf{X}_{\\text{train}}$ and  $\\mathbf{y}_{\\text{train}}$\n",
    "- $P(\\theta \\mid D)$ is the posterior distribution of the parameters - given the data.\n",
    "- $P(D \\mid \\theta)$ is the likelihood of the data given the parameters.\n",
    "- $P(\\theta)$ is the prior distribution of the parameters.\n",
    "- $P(D)$ is the marginal likelihood (evidence), a normalizing constant ensuring the posterior is a valid probability distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BayesianLinearRegressor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skpro` provides an implementation of Bayesian linear regression through the `BayesianLinearRegressor` class. Here, we create an instance of the `BayesianLinearRegressor` and fit it to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "5041e82f2cec4d18afadc01334823e21",
      "8bf13818fd184881993e49113f14aaa4",
      "aaa3b0bdfa1d49169356cde19bae9c94",
      "27aa1995a5e54ad5b61296623e65ca55",
      "140c47265a9d4413bcd5d6cb82c8813a",
      "4afa3bbfa3e94be2b99d17c0a0d236c6"
     ]
    },
    "id": "yvgLcSFQiwpV",
    "outputId": "2a2166e3-45ef-4eda-974b-61f5a09ca74a"
   },
   "outputs": [],
   "source": [
    "# data conversion and renaming to facilitate downstream analysis\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_train.columns = [\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "bayes_model = BayesianMCMCLinearRegressor()\n",
    "bayes_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0-M9HLMp2TZ"
   },
   "source": [
    "## Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bog-nh1p4LC"
   },
   "source": [
    "The prior $P(\\theta)$ reflects our beliefs about the parameters before observing any data. In Bayesian inference, the choice of prior can significantly impact the results, especially when the amount of data is limited.\n",
    "\n",
    "In the case of **`BayesianLinearRegression`**, the model includes a default prior that is **weakly informative**. A weakly informative prior is designed to provide some structure without being overly restrictive or introducing strong assumptions. \n",
    "\n",
    "You can inspect these default priors by accessing the `default_prior_config` attribute of the model instance. This attribute will show the priors assigned to parameters like the intercept, slopes, and noise variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_model.default_prior_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that they are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfpa-cWKL5aR"
   },
   "source": [
    "\\begin{align*}\n",
    "\\text{intercept} &== \\beta_{0} &\\sim \\mathcal{N}(0, 100) \\\\\n",
    "\\text{slopes} &== \\beta &\\sim \\mathcal{N}(0, 100) \\\\\n",
    "\\text{noise} &== \\sigma &\\sim \\text{HalfCauchy}(\\beta=5)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQkLzcuUAXxj"
   },
   "source": [
    "We can sample from these prior distributions using the `sample_prior` method of the `bayes_model`, specifying `numpy` arrays as the output format. The samples can then be plotted for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "NsBM2sC_q9pA",
    "outputId": "61572779-c2b6-4c21-c2c6-a123d5854973"
   },
   "outputs": [],
   "source": [
    "# get the prior samples as a dictionary of numpy arrays\n",
    "prior_samples = bayes_model.sample_prior(\"numpy\")\n",
    "\n",
    "# Plot the prior distributions\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "# Plot prior for intercept\n",
    "axes[0].hist(prior_samples[\"intercept\"], bins=80, density=True, alpha=0.75)\n",
    "axes[0].set_title(r\"Prior of Intercept $\\sim \\mathcal{N}(0, 100)$\")\n",
    "axes[0].set_xlabel(\"Intercept\")\n",
    "axes[0].set_ylabel(\"Density\")\n",
    "\n",
    "\n",
    "# Plot prior for slopes\n",
    "axes[1].hist(prior_samples[\"slopes_feature1\"], bins=80, density=True, alpha=0.75)\n",
    "axes[1].set_title(r\"Prior of Slope 1 $\\sim \\mathcal{N}(0, 100)$\")\n",
    "axes[1].set_xlabel(\"Slope - feature 1\")\n",
    "axes[1].set_ylabel(\"Density\")\n",
    "\n",
    "axes[2].hist(prior_samples[\"slopes_feature2\"], bins=80, density=True, alpha=0.75)\n",
    "axes[2].set_title(r\"Prior of Slope 2 $\\sim \\mathcal{N}(0, 100)$\")\n",
    "axes[2].set_xlabel(\"Slope - feature 2\")\n",
    "axes[2].set_ylabel(\"Density\")\n",
    "\n",
    "\n",
    "# Plot prior for sigma\n",
    "axes[3].hist(prior_samples[\"noise_var\"], bins=80, density=True, alpha=0.75)\n",
    "axes[3].set_title(r\"Prior of Sigma $\\sim HalfCauchy(5)$\")\n",
    "axes[3].set_xlabel(\"Sigma\")\n",
    "axes[3].set_ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the method `sample_prior` that we use above can return us the samples in different data types. If we wish to, we could also ask for our priors an `skpro` distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another convenient method is `get_prior_summary()` which calculates a summary statistics of our priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "wp2NeUd5FR0b",
    "outputId": "1a557f53-33c7-4090-8efd-349142dccfc3"
   },
   "outputs": [],
   "source": [
    "bayes_model.get_prior_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Elicitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default priors may not align with our beliefs, so we need to define priors that do. This process, known as **prior elicitation**, involves crafting priors that reflect domain knowledge. \n",
    "\n",
    "\n",
    "We'll use **PreliZ**, a library in the PyMC/ArviZ ecosystem, to assist with this. `PreliZ` simplifies prior elicitation by offering tools to define priors that balance domain expertise with minimal bias. While its full capabilities are beyond this tutorial’s scope, we'll demonstrate how to use it to define a prior for the intercept in a Bayesian linear regression model. \n",
    "\n",
    "\n",
    "`PreliZ` uses maximum entropy methods to incorporate real-world knowledge—like plausible baseline ranges—into the model, ensuring we choose a minimally biased prior within reasonable constraints.\n",
    "\n",
    "For example, if our domain knowledge suggests the intercept is likely close to 1, we can use `pz.maxent` to define a Normal prior where 60% of the probability mass lies within [0.8, 1.2].  We can also visually inspect this prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elicited_prior_pz, _ = pz.maxent(pz.Normal(), 0.8, 1.2, 0.6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once defined, the elicited prior can be seamlessly converted into the `Prior` class from `PyMC` - a data type required for the prior configuration of `BayesLinearRegressor` model. \n",
    "\n",
    "We can then instantiate a new `BayesianMCMCLinearRegressor` model using this elicited prior. \n",
    "Note that the other priors remain at their default values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elicited_prior = Prior(\"Normal\", mu=elicited_prior_pz.mu, sigma=elicited_prior_pz.sigma)\n",
    "\n",
    "bayes_model = BayesianMCMCLinearRegressor(prior_config={\"intercept\": elicited_prior})\n",
    "bayes_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "357km3vOvZ5H"
   },
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc1LBmZFsrdP"
   },
   "source": [
    "\n",
    "\n",
    "The likelihood function $P(D \\mid \\theta)$ represents how likely it is to observe the given data, $D$, given a set of parameters $\\theta$.\n",
    "\n",
    "For linear regression, we are assume that each observed data point $y_i$ is normally distributed around its predicted value $\\beta_0 + X_i \\beta$, with variance $\\sigma^2$.\n",
    "    \n",
    "$$P(D \\mid \\beta, \\sigma) = \\prod_{i=1}^{n} \\mathcal{N}(y_i \\mid \\beta_0 + X_i \\beta, \\sigma^2)$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y_i$ are the observed target values,\n",
    "- $X_i$ are the observed feature values,\n",
    "- $\\beta_0$ is the intercept,\n",
    "- $\\beta$ are the slopes/regression coefficients for the features,\n",
    "- $\\sigma$ is the standard deviation of the errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLgMBNm84GLT"
   },
   "source": [
    "## Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxE8vm_v4LLw"
   },
   "source": [
    "The posterior distribution, denoted as $P(\\theta \\mid D)$, represents the updated beliefs about the parameters $\\theta$ after observing the data $D$. PyMC obtains the posterior distribution using Markov Chain Monte Carlo (MCMC) algorithms, which iteratively explore the parameter space, generating a sequence of samples that approximate the posterior distribution.\n",
    "\n",
    "We can extract the posterior using the `sample_posterior` method of the `bayes_model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRskX-is8n13"
   },
   "outputs": [],
   "source": [
    "posterior_samples = bayes_model.sample_posterior(\"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the posterior distributions, we observe two key points:\n",
    "- The posterior distributions are much narrower than the initial priors, showing that the data has significantly refined our estimates.\n",
    "- The posterior means, also known as Bayesian estimates, are closer to the true values than the MLE estimates from OLS. This improvement is due to the well-specified informative prior for the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "jd21mYjJ9SQF",
    "outputId": "92859ea3-62cb-4b97-9505-bff5e5d7ea78"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))  # Same figsize as the prior plot\n",
    "\n",
    "# Calculate Bayesian estimates (mean of posterior)\n",
    "bayes_estimate_intercept = posterior_samples[\"intercept\"].mean()\n",
    "bayes_estimate_slope1 = posterior_samples[\"slopes_feature1\"].mean()\n",
    "bayes_estimate_slope2 = posterior_samples[\"slopes_feature2\"].mean()\n",
    "bayes_estimate_sigma = posterior_samples[\"noise\"].mean()\n",
    "\n",
    "# Plot posterior for intercept\n",
    "axes[0].hist(posterior_samples[\"intercept\"], bins=80, density=True, alpha=0.75)\n",
    "axes[0].axvline(\n",
    "    TRUE_INTERCEPT,\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"True Intercept: {TRUE_INTERCEPT}\",\n",
    ")\n",
    "axes[0].axvline(\n",
    "    bayes_estimate_intercept,\n",
    "    color=\"orange\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=2,\n",
    "    label=f\"Bayes Estimate: {bayes_estimate_intercept:.2f}\",\n",
    ")\n",
    "axes[0].set_title(\"Posterior of Intercept\")\n",
    "axes[0].set_xlabel(\"Intercept\")\n",
    "axes[0].set_ylabel(\"Density\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot posterior for slope feature 1\n",
    "axes[1].hist(posterior_samples[\"slopes_feature1\"], bins=80, density=True, alpha=0.75)\n",
    "axes[1].axvline(\n",
    "    TRUE_SLOPES[0],\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"True Slope (Feature 1): {TRUE_SLOPES[0]}\",\n",
    ")\n",
    "axes[1].axvline(\n",
    "    bayes_estimate_slope1,\n",
    "    color=\"orange\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=2,\n",
    "    label=f\"Bayes Estimate: {bayes_estimate_slope1:.2f}\",\n",
    ")\n",
    "axes[1].set_title(\"Posterior of Slope (Feature 1)\")\n",
    "axes[1].set_xlabel(\"Slope - feature 1\")\n",
    "axes[1].set_ylabel(\"Density\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Plot posterior for slope feature 2\n",
    "axes[2].hist(posterior_samples[\"slopes_feature2\"], bins=80, density=True, alpha=0.75)\n",
    "axes[2].axvline(\n",
    "    TRUE_SLOPES[1],\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"True Slope (Feature 2): {TRUE_SLOPES[1]}\",\n",
    ")\n",
    "axes[2].axvline(\n",
    "    bayes_estimate_slope2,\n",
    "    color=\"orange\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=2,\n",
    "    label=f\"Bayes Estimate: {bayes_estimate_slope2:.2f}\",\n",
    ")\n",
    "axes[2].set_title(\"Posterior of Slope (Feature 2)\")\n",
    "axes[2].set_xlabel(\"Slope - feature 2\")\n",
    "axes[2].set_ylabel(\"Density\")\n",
    "axes[2].legend()\n",
    "\n",
    "# Plot posterior for sigma (noise)\n",
    "axes[3].hist(posterior_samples[\"noise\"], bins=80, density=True, alpha=0.75)\n",
    "axes[3].axvline(\n",
    "    TRUE_SIGMA,\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f\"True Sigma: {TRUE_SIGMA}\",\n",
    ")\n",
    "axes[3].axvline(\n",
    "    bayes_estimate_sigma,\n",
    "    color=\"orange\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=2,\n",
    "    label=f\"Bayes Estimate: {bayes_estimate_sigma:.2f}\",\n",
    ")\n",
    "axes[3].set_title(\"Posterior of Sigma\")\n",
    "axes[3].set_xlabel(\"Sigma\")\n",
    "axes[3].set_ylabel(\"Density\")\n",
    "axes[3].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use of `get_posterior_summary()` to print out the summary statistics of our posterior.\n",
    "Note the low values of the standard deviation - indicating the 'spikiness' of our distributions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "GySjZVJp-AEW",
    "outputId": "40449077-41fe-420b-8a7f-73ba0c2163a2"
   },
   "outputs": [],
   "source": [
    "bayes_model.get_posterior_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uogi7LOhH7oR"
   },
   "source": [
    "Additionally, note that apart from using the convenience functions provided by the BayesianLinearRegressor, such as `get_posterior_summary`, you can directly access the `idata` attribute of the model instance. This 'idata' object is a container for all inference data we've used on this model so far, including the training data, the prior and the posterior. \n",
    "\n",
    "Once you have the `idata` object, you can use the `arviz` library to analyze and visualize any distributions created during the model's lifetime, such as the prior and posterior distributions. `arviz` provides a rich set of tools for diagnostics, plotting, and summarizing the results of Bayesian models. This allows for a thorough examination of the model's behavior and the reliability of the inferred parameters.\n",
    "\n",
    "For example, here, we use `arviz`'s `plot_posterior` to plot the posterior distribution of the `intercept ` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "4nYXl4CWNo6r",
    "outputId": "bfce2215-6b77-471f-ca59-d4bdabc221cb"
   },
   "outputs": [],
   "source": [
    "az.plot_posterior(bayes_model.idata, var_names=\"intercept\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n70jIDv3EKBo"
   },
   "source": [
    "# Model checking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2VKn5Kg3iBv"
   },
   "source": [
    "Before using our Bayesian model to make predictions, it is advisable to perform some sanity checks to ascertain the correctness of the model set up and the assumptions. This section describes some of the most commonly used checks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J-ZmDE2sGOm"
   },
   "source": [
    "## `graphviz` Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZZb1BcpLAo7"
   },
   "source": [
    "One way to understand the `bayes_model` is to visualize its composition using the `.visualize_model` method. This method uses the `graphviz` library to generate a graphical representation of the model, illustrating the relationships and dependencies between the priors, likelihood, data and the posterior.\n",
    "\n",
    "\n",
    "The graphviz diagram will show the following:\n",
    "\n",
    "- Ovals indicate stochastic nodes (random variables).\n",
    "- Rectangles represent deterministic nodes (computed values).\n",
    "- Shaded shapes (like the shaded ovals for X and y) indicate observed data or fixed inputs.\n",
    "- Unshaded shapes represent latent variables or parameters that the model is trying to infer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "Hs4FcW38-66-",
    "outputId": "dab0a1ef-c8d4-410a-c0c6-0d6de935f538"
   },
   "outputs": [],
   "source": [
    "# bayes_model.visualize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8VaZ4EE9NEV"
   },
   "source": [
    "## Posterior Predictive Check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytujeec43zoq"
   },
   "source": [
    "A posterior predictive check (PPC), in general, is a method used to assess the fit of a Bayesian model by comparing observed data to data simulated from the model. It helps to identify discrepancies between the model predictions and the observed data, thereby providing a way to evaluate the adequacy of the model.\n",
    "\n",
    "In our specific case, we'll use PPC to compare our target variable `y_train` versus the in-sample predictions (thin of it as `y_train_pred` generated by our model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJcKVLBVLZoG"
   },
   "source": [
    "The `BayesianLinearRegressor` class provides a convenient method, `plot_ppc` to visually perform PPC.\n",
    "\n",
    "The resulting plot will show the following components:\n",
    "\n",
    "1. **Blue Lines**: represent the posterior predictive samples, which are the range of possible values that the model predicts for the observed data, given the posterior distribution of the parameters.\n",
    "\n",
    "2. **Black Line**: represents the density of the observed data values (i.e. our `y_train`)\n",
    "\n",
    "3. **Orange Dashed Line**: represents the mean of the posterior predictive distribution, whichprovides a central tendency of the model's predictions.\n",
    "\n",
    "The plot is used to visually assess the goodness of fit of the Bayesian model. By comparing the observed data distribution (black line) to the mean of posterior predictive samples (orange dashed line), we can see if there are significant discrepancies. \n",
    "\n",
    "We can see below that the observed data closely follows the central tendency and falls within the range of the posterior predictive samples, suggesting a decent fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "gF7Fsraqr9FG",
    "outputId": "618e9e70-4fdd-4983-cb4d-274a06f46358"
   },
   "outputs": [],
   "source": [
    "bayes_model.plot_ppc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sq0u7FdvEd1V"
   },
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ0mq2TcOh1i"
   },
   "source": [
    "Now, it's time to use the trained `bayes_model` to perform out-of-sample prediction. As mentioned earlier, a significant benefit of using the Bayesian model is that it generates a full distribution for each test data point, rather than a single point estimate. This provides a more comprehensive understanding of the uncertainty and variability in the predictions.\n",
    "\n",
    "In our class, this is accomplished using the `predict_proba` method, which returns an `skpro` `Empirical` distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhZvCf9QNdQX"
   },
   "source": [
    "## `predict_proba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33,
     "referenced_widgets": [
      "2b6f7349e109440997ec97f6115eb5e8",
      "046257170ed44b08903c7ab551b34710"
     ]
    },
    "id": "wm0pwT-A8rQJ",
    "outputId": "3c0869ac-a8c2-476f-c04c-8e054c977314"
   },
   "outputs": [],
   "source": [
    "y_pred_proba_bayes = bayes_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfBP3uCNPGHa"
   },
   "source": [
    "The returned distribution is known as the **posterior predictive distribution**. This distribution provides probabilistic forecasts for future observations by incorporating uncertainty about the model parameters and data variability.\n",
    "\n",
    "The posterior predictive distribution enables us to make probabilistic statements about future observations and understand the variability in our predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EAsEgp1OC1-"
   },
   "source": [
    "\n",
    "The posterior predictive distribution is given by:\n",
    "\n",
    "$$\n",
    "p(y_{\\text{pred}} \\mid X_{\\text{new}}, X_{\\text{train}}, y_{\\text{train}}) = \\int p(y_{\\text{pred}} \\mid X_{\\text{new}}, \\theta) p(\\theta \\mid X_{\\text{train}}, y_{\\text{train}}) \\, d\\theta\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $y_{\\text{pred}}$ is the new predicted data point.\n",
    "- $X_{\\text{new}}$ is the new input.\n",
    "- $\\mathbf{X}_{\\text{train}}$ is the set of observed inputs.\n",
    "- $\\mathbf{y}_{\\text{train}}$ is the set of observed outputs.\n",
    "- $\\mathbf{\\theta}$ represents the model parameters.\n",
    "- $p(y_{\\text{pred}} | X_{\\text{new}}, \\mathbf{\\theta})$ is the likelihood of the new data point given the model parameters.\n",
    "- $p(\\mathbf{\\theta} | \\mathbf{X}_{\\text{train}}, \\mathbf{y}_{\\text{train}})$ is the posterior distribution of the model parameters given the observed data.\n",
    "\n",
    "The above equation states that to obtain the distribution of the predictions $y_{\\text{pred}}$, we need to perform two iterative sampling:\n",
    "\n",
    "1. First, we sample from the posterior distribution $p(\\theta \\mid X_{\\text{train}}, y_{\\text{train}})$\n",
    "\n",
    "2. Afterwards, for each sampled $\\theta$ from the posterior, we sample $y_{\\text{pred}}$ from the predictive distribution $p(y_{\\text{pred}} \\mid X_{\\text{new}}, \\theta)$.\n",
    "\n",
    "In practice, PyMC conveniently handles this sequential sampling process for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq1MgQKGF4_B"
   },
   "source": [
    "## `predict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEVzKOuDQc3h"
   },
   "source": [
    "If point predictions are what we're after, we've got the `predict` method to do so. Internally, this `predict` method calls the `predict_proba` method above and averages the resulting posterior predictive distribution to provide a single point estimate for each test data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222,
     "referenced_widgets": [
      "3c5c53cbd13b4cc7bba3539d0b015549",
      "8f2d3226d202475a83b7d0a5399bd4ac"
     ]
    },
    "id": "Ubr9p6ilk0Vx",
    "outputId": "cb55cae2-fb0e-40cf-afea-dff158187445"
   },
   "outputs": [],
   "source": [
    "y_pred_bayes = bayes_model.predict(X_test)\n",
    "y_pred_bayes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsMh_hqrQ2hf"
   },
   "source": [
    "## `predict_quantiles`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfT19ChHTMxB"
   },
   "source": [
    "The advantage of obtaining a full predictive distribution for our test set is that we can quantify our uncertainty by calculating quantiles. This can be conveniently achieved using the `predict_quantiles` method. Here, we use `predict_quantiles` to get the 25-th and 75-th percentiles of the posterior predictive distributions.\n",
    "\n",
    "We'll then use these quantiles to plot our predictions together with their uncertainty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253,
     "referenced_widgets": [
      "cb9ebd7e5af34a66bb4be9d0cf6676e8",
      "76228f3f57924d8099807a14a3be0f83"
     ]
    },
    "id": "ZKNeOme2I8Ms",
    "outputId": "9f34d337-c288-496e-a7eb-95cc15c834dc"
   },
   "outputs": [],
   "source": [
    "y_pred_bayes_quantiles = bayes_model.predict_quantiles(X_test, [0.25, 0.75])\n",
    "y_pred_bayes_quantiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLWYUUfsShKw"
   },
   "source": [
    "## `predict_interval`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3JDkpCcS9i0"
   },
   "source": [
    "Lastly, the model comes with the `predict_interval` method. This method returns the **credible interval**, which is a range within which a certain proportion of the posterior distribution lies. For example, a 95% credible interval for a parameter $\\theta$ means that there is a 95% probability that $\\theta$ lies within this interval, given the observed data and the prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285,
     "referenced_widgets": [
      "1bad078ae919428db9df21002e47f44d",
      "21a450b922714993904c09aa3416a5c9"
     ]
    },
    "id": "jnkLPPPySgPP",
    "outputId": "a7c8e888-2688-467a-da2e-bb41f48da1d7"
   },
   "outputs": [],
   "source": [
    "y_pred_bayes_interval = bayes_model.predict_interval(X_test, 0.95)\n",
    "y_pred_bayes_interval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix feature2 at its mean\n",
    "feature2_constant = X_test[\"feature2\"].mean()\n",
    "\n",
    "# Create a new test dataset with feature2 fixed at the constant value\n",
    "X_test_fixed_feature2 = X_test.copy()\n",
    "X_test_fixed_feature2[\"feature2\"] = feature2_constant\n",
    "\n",
    "\n",
    "# Get predictions and credible intervals from the Bayesian model\n",
    "# Assuming predict_interval gives both the mean predictions and the intervals at 95% CI\n",
    "y_pred_bayes_interval_fixed_feature2 = bayes_model.predict_interval(\n",
    "    X_test_fixed_feature2, 0.95\n",
    ")\n",
    "y_pred_bayes_fixed_feature2 = bayes_model.predict(X_test_fixed_feature2)\n",
    "\n",
    "\n",
    "# Extract mean, lower, and upper credible intervals\n",
    "credible_lower_fixed_feature2 = y_pred_bayes_interval_fixed_feature2[\"target\"][0.95][\n",
    "    \"lower\"\n",
    "]\n",
    "credible_upper_fixed_feature2 = y_pred_bayes_interval_fixed_feature2[\"target\"][0.95][\n",
    "    \"upper\"\n",
    "]\n",
    "\n",
    "# Sort X_test by 'feature1'\n",
    "sorted_indices = np.argsort(X_test_fixed_feature2[\"feature1\"])\n",
    "X_test_sorted = X_test_fixed_feature2[\"feature1\"].iloc[sorted_indices]\n",
    "y_pred_bayes_sorted = y_pred_bayes_fixed_feature2.iloc[sorted_indices]\n",
    "credible_lower_sorted = credible_lower_fixed_feature2.iloc[sorted_indices]\n",
    "credible_upper_sorted = credible_upper_fixed_feature2.iloc[sorted_indices]\n",
    "\n",
    "# Plot the predictions with the credible intervals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test_sorted, y_pred_bayes_sorted, color=\"blue\", label=\"Predicted values\")\n",
    "plt.fill_between(\n",
    "    X_test_sorted,\n",
    "    credible_lower_sorted,\n",
    "    credible_upper_sorted,\n",
    "    color=\"lightblue\",\n",
    "    alpha=0.4,\n",
    "    label=\"95% Credible Interval\",\n",
    ")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Predicted Target\")\n",
    "plt.title(\n",
    "    f\"Bayesian Predictions for X_test (Feature 2 fixed at {feature2_constant:.2f})\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcPkFWWaWv5B"
   },
   "source": [
    "# Effect of Sample Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKU_wnMHVb08"
   },
   "source": [
    "Lastly, let's take a look at how the size of training sample affects the width of the posteriors and posterior predictive distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind ourselves as to how our posterior distribution look like after we've trained our model with 20 training data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "mnCENyCf8zbi",
    "outputId": "40183b13-4505-4042-96a4-f13e9715629f"
   },
   "outputs": [],
   "source": [
    "bayes_model.get_posterior_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1l0aeM3Vr5T"
   },
   "source": [
    "How does this posterior change when we train a model with more data points?\n",
    "\n",
    "Now, let's generate a synthetic dataset with 200 datapoints and use it to train another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123,
     "referenced_widgets": [
      "b77a1bc131de475d97ff0ba200776613",
      "52c38d3a9e42417d9a1f645afe4af9f4",
      "23f5b7fa704041a8bf0026ed755ed07e",
      "1b671855504d4104b5cebff3edfc244d",
      "5969efae24fd4b1baeaf30d6bcbedfe6",
      "8955971da43241e9857ec6047c192fb5"
     ]
    },
    "id": "snDXFrdn84Sn",
    "outputId": "4315a88d-4bde-40eb-ceb0-b08eeb10530d"
   },
   "outputs": [],
   "source": [
    "N = 200\n",
    "np.random.seed(42)\n",
    "feature1 = np.random.uniform(0, 1, N)\n",
    "feature2 = np.random.uniform(0, 1, N)\n",
    "X_train = pd.DataFrame({\"feature1\": feature1, \"feature2\": feature2})\n",
    "\n",
    "\n",
    "y_true = TRUE_INTERCEPT + np.dot(X_train, TRUE_SLOPES)\n",
    "y_train = y_true + np.random.normal(0, TRUE_SIGMA, size=len(X_train))\n",
    "\n",
    "train_data = pd.concat(\n",
    "    [X_train, pd.Series(y_true, name=\"y_true\"), pd.Series(y_train, name=\"y_train\")],\n",
    "    axis=1,\n",
    ")\n",
    "train_data = train_data.sort_values(by=\"feature1\")\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "bayes_model_200 = BayesianMCMCLinearRegressor(\n",
    "    prior_config={\"intercept\": elicited_prior}\n",
    ")\n",
    "bayes_model_200.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuficUuTV0DH"
   },
   "source": [
    "We see that with this 10x increase in training set size, we obtain narrower posteriors, as evidenced by the lower `sd` values in the summary. It is noteworthy that the reduction of the standard deviation, which is around 3x, is less than the 10x reduction one might expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "l5Rlj1XLTu9E",
    "outputId": "9a5d0be8-1f99-4414-e988-5cb2fa2313a8"
   },
   "outputs": [],
   "source": [
    "bayes_model_200.get_posterior_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "4FyJcn9FWHQV",
    "outputId": "27a32c99-7a24-4e95-c03f-2e75b5872fb2"
   },
   "outputs": [],
   "source": [
    "sd_ratio = (\n",
    "    bayes_model.get_posterior_summary() / bayes_model_200.get_posterior_summary()\n",
    ")[\"sd\"]\n",
    "sd_ratio.name = \"ratio of std dev when 10x training data is used\"\n",
    "sd_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform the same experiment, this time comparing the posterior predictive distribution coming from the two models.\n",
    "\n",
    "In order to get the posterior predictive distribution from the second model (`bayes_model_500`), we first need to use it to perform prediction on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_bayes_200 = bayes_model_200.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that out of the way, let's now compare the posterior predictive distributions for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(bayes_model.idata.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(bayes_model_200.idata.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is practically no difference in the standard deviation of the posterior predictive of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    az.summary(bayes_model_200.idata.predictions)\n",
    "    / az.summary(bayes_model.idata.predictions)\n",
    ")[[\"sd\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNKM7EPXJXij"
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzuX_hc8vsD7"
   },
   "source": [
    "\n",
    "\n",
    "- [How to use the posterior predictive distribution for checking a model in PyMC](https://discourse.pymc.io/t/how-to-use-the-posterior-predictive-distribution-for-checking-a-model-from-pymc/11593/9) - A discussion on how to leverage posterior predictive checks in PyMC.\n",
    "  \n",
    "- [PyMC documentation: `sample_prior_predictive`](https://www.pymc.io/projects/docs/en/v5.15.1/api/generated/pymc.sample_prior_predictive.html) - Official PyMC documentation for generating samples from the prior predictive distribution.\n",
    "\n",
    "- [Bishop - Pattern Recognition and Machine Learning (2006)](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf) - A comprehensive reference on machine learning theory and Bayesian methods by Christopher M. Bishop.\n",
    "\n",
    "- [Updating priors](https://www.pymc.io/projects/examples/en/latest/howto/updating_priors.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
